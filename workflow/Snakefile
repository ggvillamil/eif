


## Run workflow in Docker container
## (Note: you must run snakemake command with --use-singularity flag)
container: "docker://ggvillamil/ribopipe2"


# Load libraries
import pandas as pd

## Workflow configuration
configfile: "config/config.yaml"


# Set up workflow input ---------------------------------------------------


# Read in sample sheets
ribo_samplesdf = pd.read_csv("config/ribo_samples.csv").set_index("sample_name",drop=False)
total_samplesdf = pd.read_csv("config/total_samples.csv").set_index("sample_name",drop=False)

# Test for sample name uniqueness

# Define samples
ribo_samples = list(ribo_samplesdf["sample_name"])
total_samples = list(total_samplesdf["sample_name"])

# Base name of human gtf annotation for RiboseQC
human_gtf_base = config["human_gtf"].replace(".gtf","").replace("resources/","")

# Base name of combined gtf annotation for RiboStan
gtf_base = config["gtf"].replace(".gtf","").replace("resources/","")


# One rule to rule them all -----------------------------------------------



rule all:
    input:
        expand("results/orfquant/{sample}/{sample}_final_ORFquant_results", sample = ribo_samples),


# I. Pre-process reads (trim and collapse) --------------------------------


## cutadapt_reads: use cutadapt to trim off the adapter sequence
rule cutadapt_reads:
    input:
        "data/riboseq/{sample}.fastq.gz"
    output:
        "results/cutadapt_reads/{sample}.fastq.gz"
    threads: 4
    shell:
        "zcat {input} | "
        "cutadapt --cores {threads} -a {config[adapter]} --minimum-length {config[minlength]} --maximum-length {config[maxlength]} --quality-cutoff {config[qualcutoff]} - | "
        "gzip > {output}"


## collapse_reads: collapse duplicate reads based on their UMI sequence
rule collapse_reads:
    input:
        "results/cutadapt_reads/{sample}.fastq.gz"
    output:
        "results/collapse_reads/{sample}.fastq.gz"
    log:
        "logs/cutadapt/{sample}.log"
    shell:
        "zcat {input} | "
        "workflow/scripts/collapse_reads.pl {wildcards.sample} 2> {log} | "
        "gzip > {output}"


## trim_reads: trim off UMI sequences from reads after collapsing
rule trim_reads:
    input:
        "results/collapse_reads/{sample}.fastq.gz"
    output:
        "results/trim_reads/{sample}.fastq.gz"
    log:
        "logs/trim_reads/{sample}.log"
    shell:
        "zcat {input} | "
        "workflow/scripts/remove8N_stdinout.pl 2> {log} | "
        "gzip > {output}"


# II. Remove contaminants -------------------------------------------------


# number_contaminants: assign numbers to contaminant sequences
rule number_contaminants:
    input:
        config["contaminants"]
    output:
        "results/number_contaminants/contaminants_numbered.fa"
    threads: 4
    shell:
        "Rscript workflow/scripts/number_contaminants.R {input} {output}"


# star_contaminant_index: use STAR to generate "genome" index of contaminant sequences
rule star_contaminant_index:
    input:
        "results/number_contaminants/contaminants_numbered.fa"
    output:
        directory("results/star_index/contaminants")
    params:
        extra = "--genomeSAindexNbases 9"
    threads: 8
    log:
        "logs/star/contaminant_star_index.log"
    shell:
        "STAR {params.extra} --runThreadN {threads} --runMode genomeGenerate --genomeFastaFiles {input} --genomeDir {output}"
    # wrapper:
    #     "v2.0.0/bio/star/index"


# filter_contaminants: use STAR to map reads to contaminant sequences and get unmapped reads as output
rule star_contaminant:
    input:
        fastq="results/trim_reads/{sample}.fastq.gz",
        genomeDir="results/star_index/contaminants"
    output:
        "results/filter_reads/{sample}/{sample}.fastq.gz"
    params:
        tmpDir = directory("results/filter_reads/{sample}/_tmpSTAR")
    threads: 8
    shell: r"""
        STAR \
        --genomeDir {input.genomeDir} \
        --runThreadN {threads} \
        --readFilesCommand zcat \
        --outSAMunmapped Within \
        --outMultimapperOrder Random \
        --outFilterMultimapNmax 1 \
        --alignSJoverhangMin 8 \
        --alignSJDBoverhangMin 1 \
        --outTmpDir {params.tmpDir} \
        --genomeLoad NoSharedMemory \
        --outSAMattributes NH HI AS NM MD \
        --outSAMtype SAM \
        --outFileNamePrefix {output}.contam_reads.sam \
        --outReadsUnmapped Fastx \
        --readFilesIn {input.fastq}

        gzip -c {output}.contam_reads.samUnmapped.out.mate1 > {output}
        rm -f {output}.contam_reads.samUnmapped.out.mate1
        """


# process_contam_reads:
rule process_contam_reads:
    input:
        "results/filter_reads/{sample}/{sample}.fastq.gz"
    output:
        bam="results/filter_reads/{sample}/{sample}.fastq.gz.contam_reads.bam",
        mismatch="results/filter_reads/{sample}/{sample}.fastq.gz.mm.sam",
        idxstats="results/filter_reads/{sample}/{sample}.fastq.gz.idxtmp",
        stats="results/filter_reads/{sample}/{sample}.contam_reads.bam.stats"
    threads: 8
    shell: """
        samtools view -bh {input}.contam_reads.samAligned.out.sam | \
        samtools sort -@ {threads} > {output.bam}
        samtools index {output.bam}

        samtools view -bh {output.bam} | \
        bamtools filter -tag XM:2-10 -in - -out /dev/stdout | \
        samtools view -H > {output.mismatch}

        samtools idxstats {output.bam} | \
        perl -lanpe 's/^(\S+)_[^_\s]+\t/$1\t/' > {input}.idxtmp

        samtools stats {output.bam} > {output.stats}
        """


# III. Map reads ----------------------------------------------------------


## star_genome_index: make genome index from genome FASTA file
rule star_genome_index:
    input:
        genome=config["genome"],
        gtf=config["gtf"]
    output:
        outdir=directory("results/star_index/genome"),
        forbedfile="results/star_index/genome/chrNameLength.txt"
    threads: 8
    log:
        "logs/star/genome_star_index.log"
    shell:
        "STAR --sjdbGTFfile {input.gtf} --runThreadN {threads} --runMode genomeGenerate --genomeFastaFiles {input.genome} --genomeDir {output.outdir}"


rule star_genome:
    input:
        fastq="results/filter_reads/{sample}/{sample}.fastq.gz",
        genomeDir="results/star_index/genome"
    output:
        "results/star/genome/data/{sample}/{sample}.bam"
    threads: 8
    params:
        platform = config["platform"],
        reportsDir = "results/star/genome/reports/{sample}",
        outputDir = "results/star/genome/data/{sample}"
    shell: r"""
        tmpDir=$(mktemp -d)
        mkdir -p $tmpDir/star

        STAR \
        --genomeDir {input.genomeDir} \
        --runThreadN {threads} \
        --outSAMunmapped Within \
        --outFilterType BySJout \
        --outMultimapperOrder Random \
        --alignSJoverhangMin 8 \
        --alignSJDBoverhangMin 1 \
        --outFilterMismatchNmax 999 \
        --outFilterMismatchNoverLmax 0.04 \
        --alignIntronMin 20 \
        --alignIntronMax 1000000 \
        --alignMatesGapMax 1000000 \
        --genomeLoad NoSharedMemory \
        --quantMode GeneCounts \
        --outSAMattributes NH HI AS NM MD \
        --outSAMtype BAM Unsorted \
        --outSAMattrRGline \"ID:{wildcards.sample}\" \"SM:{wildcards.sample}\" \"PL:{params.platform}\" \
        --outFileNamePrefix ${{tmpDir}}/star/ \
        --outReadsUnmapped Fastx \
        --readFilesIn {input.fastq} \
        --readFilesCommand zcat

        samtools sort -T ${{tmpDir}} -o {output} -@ {threads} ${{tmpDir}}/star/Aligned.out.bam
        samtools index {output}

        mkdir -p {params.reportsDir}
        samtools stats {output} > {params.reportsDir}/{wildcards.sample}.bamstats.txt
        samtools flagstat {output} > {params.reportsDir}/{wildcards.sample}.flagstat.log
        samtools idxstats {output} > {params.reportsDir}/{wildcards.sample}.idxstats.log

        cp ${{tmpDir}}/star/ReadsPerGene.out.tab {params.outputDir}/
        cp ${{tmpDir}}/star/SJ.out.tab {params.outputDir}/
        cp ${{tmpDir}}/star/{{Log.final.out,Log.out}} {params.reportsDir}/
        """




# IV. Check read and mapping quality --------------------------------------


## fastqc_raw: check quality of raw reads with FastQC
rule fastqc_raw:
    input:
        "data/rnaseq/{sample}_R2.fastq.gz"
    output:
        touch("results/fastqc/raw/{sample}/.done")
    params:
        outdir = "results/fastqc/raw/{sample}"
    log:
        "logs/fastqc/raw/{sample}.log"
    shell:
        "fastqc --quiet --outdir {params.outdir} {input} 2> {log}"

# the suffix _fastqc.zip is necessary for multiqc to find the file. If not using multiqc, you are free to choose an arbitrary filename

## fastqc_processed: check quality of processed reads with FastQC
rule fastqc_processed:
    input:
        "results/trim_reads/{sample}.fastq.gz"
    output:
        touch("results/fastqc/processed/{sample}/.done")
    params:
        outdir = "results/fastqc/processed/{sample}"
    log:
        "logs/fastqc/processed/{sample}.log"
    shell:
        "fastqc --quiet --outdir {params.outdir} {input} 2> {log}"


# Post-processing for normalization ---------------------------------------


rule make_bed_genome:
    input:
        "results/star_index/genome/chrNameLength.txt"
    output:
        "resources/chromosomes.bed"
    threads: 1
    shell:
        "workflow/scripts/make_bed.pl {input} > {output}"


rule split_bam_genome:
    input:
        bam="results/star/genome/data/{sample}/{sample}.bam",
        yeastchr=config["yeast_chromosomes"],
        humanchr=config["human_chromosomes"]
    output:
        yeastbam="results/split_bam/genome/yeast/{sample}.bam",
        humanbam="results/split_bam/genome/human/{sample}.bam"
    threads: 8
    shell: r"""
        samtools view -b -L {input.yeastchr} {input.bam} > {output.yeastbam}
        samtools view -b -L {input.humanchr} {input.bam} > {output.humanbam}
        """


rule split_bam_contaminant:
    input:
        bam="results/filter_reads/{sample}/{sample}.fastq.gz.contam_reads.samAligned.out.sam",
        yeastcontam=config["yeast_contaminants"],
        humancontam=config["human_contaminants"]
    output:
        yeastcontambam="results/split_bam/contaminants/yeast/{sample}.bam",
        humancontambam="results/split_bam/contaminants/human/{sample}.bam"
    threads: 8
    shell: r"""
        samtools view -b -L {input.yeastcontam} {input.bam} > {output.yeastcontambam}
        samtools view -b -L {input.humancontam} {input.bam} > {output.humancontambam}
        """

rule index_split_bam:
    input:
        "results/split_bam/{reference}/{organism}/{sample}.bam"
    output:
        "results/split_bam/{reference}/{organism}/{sample}.bam.bai"
    threads: 8
    shell:
        "samtools index {input}"


# VI. Run RiboseQC --------------------------------------------------------


rule filter_gtf:
    input:
        config["human_gtf"]
    output:
        config["human_gtf"].replace(".gtf",".filtered.gtf")
    shell:
        "zless {input} | "
        "gffread -F -T -o {output}"


rule index_genome:
    input:
        genome=config["human_genome"]
    output:
        str(config["human_genome"])+".fai"
    shell:
        "samtools faidx {input}"


rule make_riboseqc_anno:
    input:
        genome=config["human_genome"],
        genome_index=str(config["human_genome"])+".fai",
        gtf=config["human_gtf"].replace(".gtf",".filtered.gtf")
    output:
        "results/riboseqc/anno/"+human_gtf_base+".filtered.matchchrs.gtf_Rannot"
    params:
        gtfmatchchrs="results/riboseqc/anno/"+human_gtf_base+".filtered.matchchrs.gtf",
        annobase=human_gtf_base+".filtered"
    shell: r"""
        awk -vOFS="\t" '{{print $1,0,$2}}' {input.genome_index} | bedtools intersect -b - -a {input.gtf} > {params.gtfmatchchrs}

        R -e 'library(RiboseQC);
        args(prepare_annotation_files);
        prepare_annotation_files(annotation_directory = "results/riboseqc/anno", gtf_file = "{params.gtfmatchchrs}", annotation_name = "{params.annobase}", forge_BS = FALSE, genome_seq = FaFile("{input.genome}"))'
        """


rule riboseqc:
    input:
        anno="results/riboseqc/anno/"+human_gtf_base+".filtered.matchchrs.gtf_Rannot",
        bam="results/split_bam/genome/human/{sample}.bam"
    output:
        "results/riboseqc/data/{sample}/_for_ORFquant",
        report="results/riboseqc/reports/{sample}/riboseqcreport.html"
    threads: 4
    params:
        outputDir="results/riboseqc/data/{sample}/"
    shell: r"""
        R -e 'library(RiboseQC);
        RiboseQC_analysis(annotation_file = "{input.anno}", bam = "{input.bam}", rescue_all_rls = TRUE, dest_names = "{params.outputDir}", genome_seq = "{config[human_genome]}", report_file = "{output.report}")'
        """


# VII. Run ORFquant -------------------------------------------------------


rule orfquant:
    input:
        anno="results/riboseqc/anno/"+human_gtf_base+".filtered.matchchrs.gtf_Rannot",
        for_ORFquantfile="results/riboseqc/data/{sample}/_for_ORFquant"
    output:
        "results/orfquant/{sample}/{sample}_final_ORFquant_results"
    threads: 10
    resources:
        mem_mb=100000
    params:
        prefix="results/orfquant/{sample}/{sample}"
    shell: r"""
        R -e 'library(ORFquant);
        run_ORFquant(for_ORFquant_file = "{input.for_ORFquantfile}", annotation_file = "{input.anno}", n_cores = {threads}, prefix = "{params.prefix}")'
        """


# rule orfquant_plots:
#     input:
#         anno="results/riboseqc/anno/"+human_gtf_base+".filtered.matchchrs.gtf_Rannot",
#         for_ORFquantfile="results/riboseqc/data/{sample}/_for_ORFquant"
#     output:
#         "results/orfquant/{sample}/_final_ORFquant_results"
#     shell: r"""
#         R -e 'library(ORFquant);
#         plot_ORFquant_results(for_ORFquant_file = "{input.for_ORFquantfile}", ORFquant_output_file = "{output}", annotation_file = "{input.anno}")'
#         """


# rule orfquant_report:
#     input:
#         "results/orfquant/{sample}/_final_ORFquant_results/"
#     output:
#         "results/orfquant/{sample}/_ORFquant_report.html"
#     shell: r"""
#         R -e 'library(ORFquant);
#         create_ORFquant_html_report(input_files = "{input}", input_sample_names = "{wildcards.sample}", output_file = "{output}")'
#         """



# VIII. Map to transcriptome ----------------------------------------------


rule star_transcript_index:
    input:
        config["transcriptome"]
    output:
        outdir=directory("results/star_index/transcriptome"),
        forbedfile="results/star_index/transcriptome/chrNameLength.txt"
    threads: 8
    shell: r"""
        STAR \
        --runThreadN {threads} \
        --runMode genomeGenerate \
        --genomeDir {output.outdir} \
        --genomeFastaFiles {input} \
        --genomeSAindexNbases 11 \
        --genomeChrBinNbits 12
        """


rule star_transript:
    input:
        fastq="results/filter_reads/{sample}/{sample}.fastq.gz",
        transcriptindex="results/star_index/transcriptome"
    output:
        "results/star/transcriptome/data/{sample}/{sample}.bam"
    threads: 8
    params:
    shell: r"""
        tmpDir=$(mktemp -d)
        mkdir -p $tmpDir/star

        STAR \
        --runThreadN {threads} \
        --genomeDir {input.transcriptindex} \
        --outSAMtype BAM Unsorted \
        --outSAMmode NoQS \
        --outSAMattributes NH NM \
        --seedSearchLmax 10 \
        --outFilterMultimapNmax 255 \
        --outFilterMismatchNmax 1 \
        --outFilterIntronMotifs RemoveNoncanonical \
        --outFileNamePrefix results/star/transcriptome/data/{wildcards.sample}/{wildcards.sample}.transcript_ \
        --readFilesIn {input.fastq} \
        --readFilesCommand zcat

        samtools sort results/star/transcriptome/data/{wildcards.sample}/{wildcards.sample}.transcript_Aligned.out.bam -o {output}
        rm results/star/transcriptome/data/{wildcards.sample}/{wildcards.sample}.transcript_Aligned.out.bam
        samtools index {output}
        """


rule make_bed_transcriptome:
    input:
        "results/star_index/transcriptome/chrNameLength.txt"
    output:
        "resources/transcripts.bed"
    threads: 1
    shell:
        "workflow/scripts/make_bed.pl {input} > {output}"


rule split_bed_transcriptome:
    input:
        trxbed="resources/transcripts.bed",
        yeasttrx=config["yeast_transcriptome"],
        humantrx=config["human_transcriptome"]
    output:
        yeastbed="resources/yeast_transcripts.bed",
        humanbed="resources/human_transcripts.bed"
    threads: 1
    shell: r"""
        yeastcount=$(grep ">" {input.yeasttrx} | wc -l)
        tail -n $yeastcount {input.trxbed} > {output.yeastbed}

        humancount=$(grep ">" {input.humantrx} | wc -l)
        head -n $humancount {input.trxbed} > {output.humanbed}
        """


rule split_bam_transcriptome:
    input:
        bam="results/star/transcriptome/data/{sample}/{sample}.bam",
        yeasttrx="resources/yeast_transcripts.bed",
        humantrx="resources/human_transcripts.bed"
    output:
        yeastbam="results/split_bam/transcriptome/yeast/{sample}.bam",
        humanbam="results/split_bam/transcriptome/human/{sample}.bam"
    threads: 8
    shell: r"""
        samtools view -b -L {input.yeasttrx} {input.bam} > {output.yeastbam}
        samtools view -b -L {input.humantrx} {input.bam} > {output.humanbam}
        """


# VIII. Run RiboStan ------------------------------------------------------


rule ribostan_human_morfs:
    input:
        bam = "results/split_bam/transcriptome/human/{sample}.bam",
        fasta = config["human_genome"],
        gtf = config["human_gtf"]
    output:
        quant = "results/ribostan/{sample}/{sample}.ribostan.human_morf_quant.rds",
        tsv = "results/ribostan/{sample}/{sample}.ribostan.human_morf_quant.tsv"
    threads: 2
    shell: r"""
        R -e 'library(Ribostan);
        anno <- load_annotation(gtf = "{input.gtf}", fafile = "{input.fasta}", add_uorfs = FALSE);
        rpfs <- get_readgr(ribobam = "{input.bam}", anno);
        offsets_df <- get_offsets(rpfs, anno);
        psites <- get_psite_gr(rpfs, offsets_df, anno);
        ritpms <- get_ritpms(psites, anno);
        n_reads <- dplyr::n_distinct(names(rpfs));
        lengths <- GenomicRanges::width(anno$trspacecds[names(ritpms)]);
        nucfracs <- (ritpms * lengths);
        nucfracs <- nucfracs / sum(nucfracs);
        counts <- n_reads * nucfracs;
        counts <- tibble::enframe(counts, "Name", "NumReads");
        ritpmdf <- tibble::enframe(ritpms, "Name", "ritpm");
        cdslens <- anno$trspacecds %>%
            GenomicRanges::width() %>%
            setNames(names(anno$trspacecds)) %>%
            tibble::enframe("Name", "Length") %>%
            dplyr::mutate(EffectiveLength = .data$Length);
        output <- cdslens %>%
            dplyr::left_join(ritpmdf) %>%
            dplyr::left_join(counts);
        saveRDS(ritpms, file = "{output.quant}");
        output %>% readr::write_tsv("{output.tsv}")'
        """


rule get_offsets:
    input:
        bam = "results/split_bam/transcriptome/human/{sample}.bam",
        fasta = config["human_genome"],
        gtf = config["human_gtf"]
    output:
        "results/ribostan/{sample}/{sample}.ribostan.human_offsets.rds"
    threads: 2
    shell: r"""
        R -e 'library(Ribostan);
        anno <- load_annotation(gtf = "{input.gtf}", fafile = "{input.fasta}", add_uorfs = FALSE);
        rpfs <- get_readgr(ribobam = "{input.bam}", anno);
        offsets_df <- get_offsets(rpfs, anno);
        saveRDS(offsets_df, file = "{output}")'
        """


rule ribostan_yeast_morfs:
    input:
        bam = "results/split_bam/transcriptome/yeast/{sample}.bam",
        fasta = config["yeast_genome"],
        gtf = config["yeast_gtf"],
        offsets = "results/ribostan/{sample}/{sample}.ribostan.human_offsets.rds"
    output:
        quant = "results/ribostan/{sample}/{sample}.ribostan.yeast_morf_quant.rds",
        tsv = "results/ribostan/{sample}/{sample}.ribostan.yeast_morf_quant.tsv"
    threads: 2
    shell: r"""
        R -e 'library(Ribostan);
        anno <- load_annotation(gtf = "{input.gtf}", fafile = "{input.fasta}", add_uorfs = FALSE);
        rpfs <- get_readgr(ribobam = "{input.bam}", anno);
        offsets_df <- readRDS(file = "{input.offsets}");
        psites <- get_psite_gr(rpfs, offsets_df, anno);
        ritpms <- get_ritpms(psites, anno);
        n_reads <- dplyr::n_distinct(names(rpfs));
        lengths <- GenomicRanges::width(anno$trspacecds[names(ritpms)]);
        nucfracs <- (ritpms * lengths);
        nucfracs <- nucfracs / sum(nucfracs);
        counts <- n_reads * nucfracs;
        counts <- tibble::enframe(counts, "Name", "NumReads");
        ritpmdf <- tibble::enframe(ritpms, "Name", "ritpm");
        cdslens <- anno$trspacecds %>%
            GenomicRanges::width() %>%
            setNames(names(anno$trspacecds)) %>%
            tibble::enframe("Name", "Length") %>%
            dplyr::mutate(EffectiveLength = .data$Length);
        output <- cdslens %>%
            dplyr::left_join(ritpmdf) %>%
            dplyr::left_join(counts);
        saveRDS(ritpms, file = "{output.quant}");
        output %>% readr::write_tsv("{output.tsv}")'
        """


rule ribostan_human_uorfs:
    input:
        bam = "results/split_bam/transcriptome/human/{sample}.bam",
        fasta = config["human_genome"],
        gtf = config["human_gtf"]
    output:
        anno = "results/ribostan/{sample}/{sample}.ribostan.human_anno.rds",
        rpfs = "results/ribostan/{sample}/{sample}.ribostan.human_rpfs.rds",
        offsets_df = "results/ribostan/{sample}/{sample}.ribostan.human_offsets_df.rds",
        psites = "results/ribostan/{sample}/{sample}.ribostan.human_psites.rds",
        filtered_anno = "results/ribostan/{sample}/{sample}.ribostan.human_filtered_anno.rds",
        uorf_anno = "results/ribostan/{sample}/{sample}.ribostan.human_uorf_anno.rds",
        quant = "results/ribostan/{sample}/{sample}.ribostan.human_uorf_quant.rds",
        tsv = "results/ribostan/{sample}/{sample}.ribostan.human_uorf_quant.tsv"
    threads: 2
    shell: r"""
        R -e 'library(Ribostan);
        anno <- load_annotation(gtf = "{input.gtf}", fafile = "{input.fasta}", add_uorfs = TRUE);
        saveRDS(anno, file = "{output.anno}");
        rpfs <- get_readgr(ribobam = "{input.bam}", anno);
        saveRDS(rpfs, file = "{output.rpfs}");
        offsets_df <- get_offsets(rpfs, anno);
        saveRDS(offsets_df, file = "{output.offsets_df}");
        psites <- get_psite_gr(rpfs, offsets_df, anno);
        saveRDS(psites, file = "{output.psites}");
        filtered_anno <- periodicity_filter_uORFs(psites, anno, remove=TRUE);
        saveRDS(filtered_anno, file = "{output.filtered_anno}");
        uorfgrl <- filtered_anno$cdsgrl[filtered_anno$uORF];
        saveRDS(uorfgrl, file = "{output.uorf_anno}");
        ritpms <- get_ritpms(psites, filtered_anno);
        uorf_ritpms <- ritpms[names(uorfgrl)];
        n_reads <- dplyr::n_distinct(names(rpfs));
        lengths <- GenomicRanges::width(filtered_anno$trspacecds[names(uorf_ritpms)]);
        nucfracs <- (uorf_ritpms * lengths);
        nucfracs <- nucfracs / sum(nucfracs);
        counts <- n_reads * nucfracs;
        counts <- tibble::enframe(counts, "Name", "NumReads");
        ritpmdf <- tibble::enframe(ritpms, "Name", "ritpm");
        uorflens <- filtered_anno$trspacecds[names(uorf_ritpms)] %>%
            GenomicRanges::width() %>%
            setNames(names(filtered_anno$trspacecds[names(uorf_ritpms)])) %>%
            tibble::enframe("Name", "Length") %>%
            dplyr::mutate(EffectiveLength = .data$Length);
        output <- uorflens %>%
            dplyr::left_join(ritpmdf) %>%
            dplyr::left_join(counts);
        saveRDS(uorf_ritpms, file = "{output.quant}");
        output %>% readr::write_tsv("{output.tsv}")'
        """


# IX. Run Salmon ----------------------------------------------------------


rule salmon_transcript_index:
    input:
        config["transcriptome"]
    output:
        directory("results/salmon_index/transcriptome")
    threads: 8
    shell:
        "salmon index -p {threads} -k 21 -t {input} -i {output}"


rule salmon_pe:
    input:
        fastq1="data/rnaseq/{totalRNA_sample}_R1.fastq.gz",
        fastq2="data/rnaseq/{totalRNA_sample}_R2.fastq.gz",
        salmonindex="results/salmon_index/transcriptome"
    output:
        "results/salmon/data/{totalRNA_sample}/quant.sf"
    threads: 4
    params:
        lib="A"
    shell: r"""
        salmon quant \
        -p {threads} \
        --seqBias \
        -i {input.salmonindex} \
        -l {params.lib} \
        -1 <(zcat {input.fastq1}) \
        -2 <(zcat {input.fastq2}) \
        --output results/salmon/data/{wildcards.totalRNA_sample} \
        --validateMappings
        """



